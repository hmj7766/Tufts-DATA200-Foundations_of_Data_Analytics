{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39948e85-4de5-4c0e-81bd-ea2d9293fafc",
   "metadata": {},
   "source": [
    "## Homework 7\n",
    "\n",
    "### Author: Hannah Marr\n",
    "\n",
    "### DATA 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caeac69-0f81-4436-b51a-87113a022246",
   "metadata": {},
   "source": [
    "## II - Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085a47f1-5f53-4e30-a60b-c63069e3cbd1",
   "metadata": {},
   "source": [
    "You are required to work with the loan.csv dataset, which will be used to predict the status of a loan (loan status) based on various predictor variables included in the dataset. You are free to build your model using Python or R.\n",
    "\n",
    "Variables:\n",
    "* The response variable is: Y = loan status\n",
    "* The predictor variables we are interested in are all other variables in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eababeb6-4577-4999-a2e0-66debbde4dae",
   "metadata": {},
   "source": [
    "1. Begin by cleaning the dataset: remove all rows containing null values. Next, convert all categorical features into numeric formats suitable for modeling. Ensure that the dataset is balanced with respect to the response variable loan status to prevent any bias in prediction outcomes. Finally, split the dataset into a training set (70%) and a testing set (30%), and display the shape of each to confirm the split. Provide the code. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c322e543-ddcf-44c1-8c35-dbec4438dcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>35000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>B</td>\n",
       "      <td>6000</td>\n",
       "      <td>11.49</td>\n",
       "      <td>0.17</td>\n",
       "      <td>N</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>56000</td>\n",
       "      <td>OWN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>C</td>\n",
       "      <td>4000</td>\n",
       "      <td>13.35</td>\n",
       "      <td>0.07</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>28800</td>\n",
       "      <td>OWN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>PERSONAL</td>\n",
       "      <td>A</td>\n",
       "      <td>6000</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.21</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>70000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>14.0</td>\n",
       "      <td>VENTURE</td>\n",
       "      <td>B</td>\n",
       "      <td>12000</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>60000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>A</td>\n",
       "      <td>6000</td>\n",
       "      <td>6.92</td>\n",
       "      <td>0.10</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "0   0          37          35000                  RENT                0.0   \n",
       "1   1          22          56000                   OWN                6.0   \n",
       "2   2          29          28800                   OWN                8.0   \n",
       "3   3          30          70000                  RENT               14.0   \n",
       "4   4          22          60000                  RENT                2.0   \n",
       "\n",
       "  loan_intent loan_grade  loan_amnt  loan_int_rate  loan_percent_income  \\\n",
       "0   EDUCATION          B       6000          11.49                 0.17   \n",
       "1     MEDICAL          C       4000          13.35                 0.07   \n",
       "2    PERSONAL          A       6000           8.90                 0.21   \n",
       "3     VENTURE          B      12000          11.11                 0.17   \n",
       "4     MEDICAL          A       6000           6.92                 0.10   \n",
       "\n",
       "  cb_person_default_on_file  cb_person_cred_hist_length  loan_status  \n",
       "0                         N                          14            0  \n",
       "1                         N                           2            0  \n",
       "2                         N                          10            0  \n",
       "3                         N                           5            0  \n",
       "4                         N                           3            0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"/Users/hannahmarr/Desktop/Tufts/DATA200/Homeworks/loan.csv\"\n",
    "loan = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to understand the structure of the dataset\n",
    "loan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b03c6d1-f227-4290-a2ea-c74f18d5e34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Data Cleaning - Remove rows with null values\n",
    "loan_cleaned = loan.dropna()\n",
    "\n",
    "loan_cleaned.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7893439-5614-4d38-9a63-76f606e636e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58645 entries, 0 to 58644\n",
      "Data columns (total 13 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   id                          58645 non-null  int64  \n",
      " 1   person_age                  58645 non-null  int64  \n",
      " 2   person_income               58645 non-null  int64  \n",
      " 3   person_home_ownership       58645 non-null  object \n",
      " 4   person_emp_length           58645 non-null  float64\n",
      " 5   loan_intent                 58645 non-null  object \n",
      " 6   loan_grade                  58645 non-null  object \n",
      " 7   loan_amnt                   58645 non-null  int64  \n",
      " 8   loan_int_rate               58645 non-null  float64\n",
      " 9   loan_percent_income         58645 non-null  float64\n",
      " 10  cb_person_default_on_file   58645 non-null  object \n",
      " 11  cb_person_cred_hist_length  58645 non-null  int64  \n",
      " 12  loan_status                 58645 non-null  int64  \n",
      "dtypes: float64(3), int64(6), object(4)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Encode Categorical Variables\n",
    "loan_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f02b614-8429-407f-8058-989da6fd3666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'person_home_ownership': {'MORTGAGE': 0, 'OTHER': 1, 'OWN': 2, 'RENT': 3},\n",
       " 'loan_intent': {'DEBTCONSOLIDATION': 0,\n",
       "  'EDUCATION': 1,\n",
       "  'HOMEIMPROVEMENT': 2,\n",
       "  'MEDICAL': 3,\n",
       "  'PERSONAL': 4,\n",
       "  'VENTURE': 5},\n",
       " 'loan_grade': {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6},\n",
       " 'cb_person_default_on_file': {'N': 0, 'Y': 1}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset the loan_cleaned data to ensure correct mappings\n",
    "loan_cleaned = loan.dropna()\n",
    "\n",
    "# Dictionary to store the mapping of original categories to their encoded numeric values\n",
    "encoding_mappings = {}\n",
    "\n",
    "# Apply label encoding to each categorical column with mapping to original names\n",
    "for feature in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    loan_cleaned[feature] = le.fit_transform(loan_cleaned[feature])\n",
    "    label_encoders[feature] = le\n",
    "\n",
    "    # Create a mapping of original category names to their encoded numeric values\n",
    "    mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    encoding_mappings[feature] = mapping\n",
    "\n",
    "# Check encoding mappings to ensure they map from original category names to numeric values\n",
    "encoding_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "26acadca-d999-4643-905b-4fcd5e1a9d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_status\n",
       "0    50295\n",
       "1     8350\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Balancing the Dataset\n",
    "# Check the distribution of the target variable 'loan_status' before balancing\n",
    "distribution_before = loan_cleaned['loan_status'].value_counts()\n",
    "distribution_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f1515aeb-6ba6-457a-887e-5a139106a39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8350"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the minimum count between the two classes to balance the dataset\n",
    "min_count = distribution_before.min()\n",
    "min_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ad30471b-e24e-4291-81b4-194ce1f1ac39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_status\n",
       "0    8350\n",
       "1    8350\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downsample the majority class (class 0) to match the minority class (class 1)\n",
    "balanced_df = pd.concat([\n",
    "    loan_cleaned[loan_cleaned['loan_status'] == 0].sample(n=min_count, random_state=42),\n",
    "    loan_cleaned[loan_cleaned['loan_status'] == 1].sample(n=min_count, random_state=42)\n",
    "])\n",
    "\n",
    "# Check the distribution of the target variable 'loan_status' after balancing\n",
    "distribution_after = balanced_df['loan_status'].value_counts()\n",
    "\n",
    "distribution_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fcb13ec3-cc0c-44ce-8d01-43d5ecfe6ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Splitting the Dataset\n",
    "# Define the features (X) and the target variable (y)\n",
    "X = balanced_df.drop(columns=['loan_status', 'id'])  # Exclude 'loan_status' (target) and 'id' (irrelevant)\n",
    "y = balanced_df['loan_status']\n",
    "\n",
    "# Split the dataset into training (70%) and testing (30%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "38fe4a40-bda6-40af-a83f-a3cc3501ddb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Null Counts Before Removal': 0,\n",
       " 'Null Counts After Removal': 0,\n",
       " 'Encoded Features': ['person_home_ownership',\n",
       "  'loan_intent',\n",
       "  'loan_grade',\n",
       "  'cb_person_default_on_file'],\n",
       " 'Class Distribution Before Balancing': {0: 50295, 1: 8350},\n",
       " 'Class Distribution After Balancing': {0: 8350, 1: 8350},\n",
       " 'Training Set Shape': (11690, 11),\n",
       " 'Testing Set Shape': (5010, 11),\n",
       " 'Encoding Mappings': {'person_home_ownership': {'MORTGAGE': 0,\n",
       "   'OTHER': 1,\n",
       "   'OWN': 2,\n",
       "   'RENT': 3},\n",
       "  'loan_intent': {'DEBTCONSOLIDATION': 0,\n",
       "   'EDUCATION': 1,\n",
       "   'HOMEIMPROVEMENT': 2,\n",
       "   'MEDICAL': 3,\n",
       "   'PERSONAL': 4,\n",
       "   'VENTURE': 5},\n",
       "  'loan_grade': {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6},\n",
       "  'cb_person_default_on_file': {'N': 0, 'Y': 1}}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Summary Report\n",
    "# This dictionary provides a quick overview of the preprocessing steps and results\n",
    "summary = {\n",
    "    \"Null Counts Before Removal\": loan.isnull().sum().sum(),\n",
    "    \"Null Counts After Removal\": loan_cleaned.isnull().sum().sum(),\n",
    "    \"Encoded Features\": categorical_features,\n",
    "    \"Class Distribution Before Balancing\": distribution_before.to_dict(),\n",
    "    \"Class Distribution After Balancing\": distribution_after.to_dict(),\n",
    "    \"Training Set Shape\": X_train.shape,\n",
    "    \"Testing Set Shape\": X_test.shape,\n",
    "    \"Encoding Mappings\": encoding_mappings,\n",
    "}\n",
    "\n",
    "# Output the summary report with encoding mappings\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613ecaa3-700b-493d-bb5a-6929d018c0aa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b740add-7c09-49fe-baaf-18e2b7083fcc",
   "metadata": {},
   "source": [
    "2. Construct a neural network model with at least one hidden layer to predict loan status. Compile and train your model using the training dataset. After training, use the model to predict loan status on the test dataset. Evaluate your model’s performance by calculating its accuracy and generating a confusion matrix. If the initial model accuracy is below 85%, adjust and tune your model to achieve at least 85% accuracy. Provide the code (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e780c08-9c17-4789-ab25-8aa2c15fc4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "04e794dc-aa37-47b4-ac01-513103cc4867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the Neural Network Model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)),  # Input layer with the number of features\n",
    "    tf.keras.layers.Dense(64, activation='relu'),      # Hidden layer with 64 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(32, activation='relu'),      # Additional hidden layer with 32 neurons\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')     # Output layer with a single neuron for binary classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b3f362e0-8e27-481a-8001-b94830108116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Compile the Model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ee89dc1e-73ac-4c0e-a7fd-7fba00e8f668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - accuracy: 0.6009 - loss: 66.8607 - val_accuracy: 0.6861 - val_loss: 38.2591\n",
      "Epoch 2/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.6332 - loss: 34.8976 - val_accuracy: 0.6882 - val_loss: 19.2685\n",
      "Epoch 3/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291us/step - accuracy: 0.6294 - loss: 29.5085 - val_accuracy: 0.6886 - val_loss: 63.2716\n",
      "Epoch 4/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.6597 - loss: 28.9098 - val_accuracy: 0.6938 - val_loss: 31.2412\n",
      "Epoch 5/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289us/step - accuracy: 0.6350 - loss: 41.6698 - val_accuracy: 0.7083 - val_loss: 12.4609\n",
      "Epoch 6/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283us/step - accuracy: 0.6376 - loss: 27.9690 - val_accuracy: 0.7126 - val_loss: 6.8060\n",
      "Epoch 7/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284us/step - accuracy: 0.6355 - loss: 33.8421 - val_accuracy: 0.6125 - val_loss: 50.3393\n",
      "Epoch 8/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step - accuracy: 0.6331 - loss: 30.3360 - val_accuracy: 0.6228 - val_loss: 26.0874\n",
      "Epoch 9/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280us/step - accuracy: 0.6649 - loss: 16.3370 - val_accuracy: 0.7382 - val_loss: 6.0775\n",
      "Epoch 10/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286us/step - accuracy: 0.6657 - loss: 19.5604 - val_accuracy: 0.5205 - val_loss: 47.8162\n",
      "Epoch 11/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286us/step - accuracy: 0.6499 - loss: 25.2686 - val_accuracy: 0.7280 - val_loss: 10.7307\n",
      "Epoch 12/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step - accuracy: 0.6735 - loss: 16.9086 - val_accuracy: 0.7113 - val_loss: 18.3135\n",
      "Epoch 13/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.6619 - loss: 21.4767 - val_accuracy: 0.6642 - val_loss: 21.2583\n",
      "Epoch 14/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290us/step - accuracy: 0.6507 - loss: 22.5497 - val_accuracy: 0.6908 - val_loss: 11.4538\n",
      "Epoch 15/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.6574 - loss: 19.1153 - val_accuracy: 0.7532 - val_loss: 7.6793\n",
      "Epoch 16/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step - accuracy: 0.6801 - loss: 13.9704 - val_accuracy: 0.7310 - val_loss: 12.5033\n",
      "Epoch 17/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284us/step - accuracy: 0.6618 - loss: 18.3372 - val_accuracy: 0.6942 - val_loss: 30.8659\n",
      "Epoch 18/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.6769 - loss: 18.7328 - val_accuracy: 0.4957 - val_loss: 19.7368\n",
      "Epoch 19/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step - accuracy: 0.6804 - loss: 15.8012 - val_accuracy: 0.7216 - val_loss: 8.7072\n",
      "Epoch 20/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - accuracy: 0.6732 - loss: 13.5992 - val_accuracy: 0.6476 - val_loss: 33.6958\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Train the Model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "95896f9e-6493-41ff-980e-3069781bea87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264us/step\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Make Predictions on the Test Set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bcc77972-e67b-47fe-9b9e-b7fbb3e874b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Evaluate the Model's Performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "68998cc7-03fd-4e77-a7a2-46fbfa4a615d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6512974051896208"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "25654f44-9ba5-40b6-a146-56e34f8cf4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2503,   40],\n",
       "       [1707,  760]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2c70dc9c-b26e-4257-a2ae-f86adc98a763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial model accuracy: 0.61. Tuning the model for better performance...\n",
      "Epoch 1/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.6037 - loss: 127.6519 - val_accuracy: 0.6861 - val_loss: 26.0318\n",
      "Epoch 2/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.6161 - loss: 32.1337 - val_accuracy: 0.4957 - val_loss: 49.5989\n",
      "Epoch 3/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.6171 - loss: 27.1175 - val_accuracy: 0.5945 - val_loss: 45.1975\n",
      "Epoch 4/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.6315 - loss: 22.3616 - val_accuracy: 0.5749 - val_loss: 19.1968\n",
      "Epoch 5/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.6321 - loss: 9.4002 - val_accuracy: 0.6125 - val_loss: 24.1512\n",
      "Epoch 6/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.6361 - loss: 11.0938 - val_accuracy: 0.6702 - val_loss: 5.3719\n",
      "Epoch 7/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.6529 - loss: 5.2727 - val_accuracy: 0.6565 - val_loss: 4.3385\n",
      "Epoch 8/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.6608 - loss: 4.5793 - val_accuracy: 0.6382 - val_loss: 2.0445\n",
      "Epoch 9/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.6710 - loss: 2.2349 - val_accuracy: 0.7263 - val_loss: 1.2770\n",
      "Epoch 10/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.6622 - loss: 1.9329 - val_accuracy: 0.7271 - val_loss: 1.0105\n",
      "Epoch 11/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.6862 - loss: 1.3722 - val_accuracy: 0.7395 - val_loss: 0.8172\n",
      "Epoch 12/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.6655 - loss: 1.5012 - val_accuracy: 0.7421 - val_loss: 0.7071\n",
      "Epoch 13/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.6778 - loss: 1.1819 - val_accuracy: 0.6993 - val_loss: 0.9327\n",
      "Epoch 14/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.6691 - loss: 1.5254 - val_accuracy: 0.5547 - val_loss: 1.0523\n",
      "Epoch 15/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.6784 - loss: 0.8018 - val_accuracy: 0.7297 - val_loss: 0.5805\n",
      "Epoch 16/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - accuracy: 0.6791 - loss: 0.7128 - val_accuracy: 0.7190 - val_loss: 0.5596\n",
      "Epoch 17/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.6720 - loss: 0.7102 - val_accuracy: 0.5727 - val_loss: 2.8125\n",
      "Epoch 18/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.6585 - loss: 0.9426 - val_accuracy: 0.6933 - val_loss: 0.6430\n",
      "Epoch 19/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - accuracy: 0.6978 - loss: 0.6198 - val_accuracy: 0.6972 - val_loss: 0.6567\n",
      "Epoch 20/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - accuracy: 0.6974 - loss: 0.6724 - val_accuracy: 0.7203 - val_loss: 0.6095\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238us/step\n"
     ]
    }
   ],
   "source": [
    "# Step 6: If Accuracy is Below 85%, Adjust and Tune the Model\n",
    "if accuracy < 0.85:\n",
    "    print(f\"Initial model accuracy: {accuracy:.2f}. Tuning the model for better performance...\")\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "    # Re-evaluate the model\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da1f909-9889-4b33-9db8-a455e3e96eea",
   "metadata": {},
   "source": [
    "The above model was used to get a sense for what the initial model would look like. Below, I use keras_tuner to attempt to achieve an accuracy of at least 85%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "afff1d2a-9de8-43c0-bdc2-db656a639e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 00m 25s]\n",
      "val_accuracy: 0.8327630460262299\n",
      "\n",
      "Best val_accuracy So Far: 0.8556458353996277\n",
      "Total elapsed time: 00h 29m 02s\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step\n",
      "Final model accuracy: 0.84\n",
      "Confusion Matrix:\n",
      "[[2314  229]\n",
      " [ 569 1898]]\n",
      "Best Hyperparameters: {'num_layers': 3, 'units_0': 128, 'dropout_0': 0.3449331189458029, 'units_1': 96, 'dropout_1': 0.45678181655456535, 'learning_rate': 0.0010955889746809093, 'optimizer': 'adam', 'units_2': 192, 'dropout_2': 0.3100762335664318, 'units_3': 96, 'dropout_3': 0.47165823837787546}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Step 1: Data Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 2: Define the Model Building Function for Keras Tuner\n",
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(X_train_scaled.shape[1],)))\n",
    "\n",
    "    # Hyperparameter choices for the number of layers and neurons\n",
    "    for i in range(hp.Int('num_layers', 2, 4)):\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            units=hp.Int(f'units_{i}', min_value=32, max_value=256, step=32),\n",
    "            activation='relu'\n",
    "        ))\n",
    "        model.add(tf.keras.layers.Dropout(rate=hp.Float(f'dropout_{i}', 0.2, 0.5)))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Hyperparameter choice for optimizer and learning rate\n",
    "    learning_rate = hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')\n",
    "    optimizer = hp.Choice('optimizer', ['adam', 'RMSprop', 'SGD'])\n",
    "\n",
    "    if optimizer == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'RMSprop':\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Step 3: Custom Callback Using tf.keras.callbacks.Callback\n",
    "class StopOn85PercentAccuracy(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        accuracy = logs.get(\"val_accuracy\")\n",
    "        if accuracy is not None and accuracy >= 0.85:\n",
    "            print(\"Desired accuracy of 85% achieved. Stopping search.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# Initialize the Keras Tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=100,  # Allow enough trials to search effectively\n",
    "    executions_per_trial=2,  # Number of times to train each model\n",
    "    directory='my_dir',\n",
    "    project_name='loan_status_prediction'\n",
    ")\n",
    "\n",
    "# Step 4: Search for the Best Hyperparameters with early stopping and custom callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "stop_on_accuracy = StopOn85PercentAccuracy()\n",
    "\n",
    "tuner.search(X_train_scaled, y_train, epochs=50, validation_split=0.2,\n",
    "             callbacks=[early_stopping, stop_on_accuracy], verbose=1)\n",
    "\n",
    "# Step 5: Retrieve the Best Model and Evaluate\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Make Predictions on the Test Set\n",
    "y_pred_prob = best_model.predict(X_test_scaled)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "# Evaluate the Model's Performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Final model accuracy: {accuracy:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Print the Best Hyperparameters\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb3cb33-4c94-48d5-b5bb-064bfcd96dcf",
   "metadata": {},
   "source": [
    "In this and previous iterations of hyperparameter tuning that I tested, I was not able to get a model accuracy above 84%. However, given that the highest val_accuracy is above 85%, I am determining this to be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672c3695-dc21-4aef-bb8c-a2723b233a88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
